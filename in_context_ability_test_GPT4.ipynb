{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrvOw5egsQTv",
        "outputId": "174522ea-ff1c-4eaf-b474-293ce23fdafe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.30.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "api_key= # Replace with YOUR API key!\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('cc_data_seq.csv')\n",
        "#data['Event'] = data['Event'].str.replace('_', '', regex=False)\n",
        "data['Event'] = data['Event'].str.replace('0_0_0,', '', regex=False)\n",
        "data['Event'] = data['Event'].str.replace('start,', '', regex=False)\n",
        "data['Event'] = data['Event'].str.replace('end', '', regex=False)\n",
        "def add_two_to_numbers(s):\n",
        "    parts = s.split('_')\n",
        "    if len(parts)>1:\n",
        "        parts = [str(int(part) + 2) for part in parts]\n",
        "        return ''.join(parts)\n",
        "    else:\n",
        "        return s\n",
        "\n",
        "data['Event'] = data['Event'].apply(lambda y: ','.join([add_two_to_numbers(x) for x in y.split(',')]))\n",
        "print(data.head(), len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGsUf94YinyQ",
        "outputId": "bc7913aa-afb6-44b8-c729-f04a2ac3731d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Unnamed: 0               ID  Response  \\\n",
            "0  ARE000000200039  ARE000000200039         0   \n",
            "1  ARE000000200051  ARE000000200051         1   \n",
            "2  ARE000000300079  ARE000000300079         1   \n",
            "3  ARE000000400093  ARE000000400093         1   \n",
            "4  ARE000000400117  ARE000000400117         0   \n",
            "\n",
            "                                               Event  \\\n",
            "0  340,444,444,444,444,444,440,440,400,000,000,00...   \n",
            "1  reset,122,112,111,122,122,reset,422,reset,242,...   \n",
            "2                 333,reset,223,reset,232,reset,322,   \n",
            "3  322,reset,223,224,reset,232,242,142,reset,422,...   \n",
            "4                           040,000,111,422,242,224,   \n",
            "\n",
            "                                                Time  \n",
            "0  0,49.3,55.9,61.7,62.6,63.2,63.5,63.9,66.4,68.4...  \n",
            "1  0,98.9,151.9,156.7,160.5,164.8,165.8,166.7,170...  \n",
            "2      0,113.2,119.1,122,135.4,138.5,147.8,149.8,157  \n",
            "3  0,36.9,41.2,43.3,44.5,50.5,61.9,66.1,68.7,72.3...  \n",
            "4  0,59.9,91.8000000000001,99.6999999999999,113.1...   16763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = 200 # training data size\n",
        "num_val = 100   # validation data size\n",
        "dat_train_val, dat_test = train_test_split(data, test_size=len(data)-(num_train + num_val), random_state=523, shuffle=True)\n",
        "dat_train, dat_val = train_test_split(dat_train_val, test_size=num_val, random_state=523, shuffle=True)\n",
        "\n",
        "training_events = set(dat_train['Event'])\n",
        "# Count how many validation events are exactly in the training set\n",
        "# ncount_exact_matches = dat_val['Event'].apply(lambda x: x in training_events).sum()\n",
        "# print(f\"Number of validation samples with events exactly in the training set: {count_exact_matches}\")\n",
        "\n",
        "len(dat_train), len(dat_val), len(dat_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW7zQYU6sdmY",
        "outputId": "d78babd7-f35d-41d6-9fe3-4e0cab02dd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 100, 16463)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompts(training_data, validation_data):\n",
        "    formatted_training = [\"Input: {}; Label: {}\".format(event, resp) for event, resp in zip(training_data['Event'], training_data['Response'])]\n",
        "    training_concatenated = \" \".join(formatted_training)\n",
        "    prompts = []\n",
        "    labels_val = []\n",
        "    for event, resp in zip(validation_data['Event'], validation_data['Response']):\n",
        "        prompt = training_concatenated + \" \" + \"Input: {}; Label: \".format(event)\n",
        "        prompts.append(prompt)\n",
        "        labels_val.append(resp)\n",
        "    return prompts, labels_val\n",
        "\n",
        "prompts_incontext, labels_val = create_prompts(dat_train, dat_val)\n",
        "len(prompts_incontext), labels_val[0]#, prompts_incontext[0]\n",
        "\n",
        "def create_chat_prompts(system_message, prompts_tmp):\n",
        "    training_messages = []\n",
        "    for prompt_i in prompts_tmp:\n",
        "        prompt_one_valsample = [\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": prompt_i}\n",
        "        ]\n",
        "        training_messages.append(prompt_one_valsample)\n",
        "    return training_messages\n",
        "\n",
        "system_message = \"You are a helpful assistant designed to find hidden rules from the Input data to do binary classification. \" \\\n",
        "                 \"You need to first learn from the labeled data and predict the label of the last Input. \" \\\n",
        "                 \"Think it step by step but only answer 0 or 1.\"\n",
        "prompts = create_chat_prompts(system_message, prompts_incontext)\n",
        "len(prompts), prompts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCGv1q4vs2mV",
        "outputId": "7fadbf94-24c0-4ba3-dbe0-b163962d7313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,\n",
              " [{'role': 'system',\n",
              "   'content': 'You are a helpful assistant designed to find hidden rules from the Input data to do binary classification. You need to first learn from the labeled data and predict the label of the last Input. Think it step by step but only answer 0 or 1.'},\n",
              "  {'role': 'user',\n",
              "   'content': 'Input: 122,422,444,440,400,reset,223,232,322,reset,322,reset,reset,232,reset,223,; Label: 1 Input: ; Label: 0 Input: 434,444,422,322,422,422,422,422,422,reset,322,422,reset,242,reset,224,; Label: 1 Input: 341,444,333,000,101,322,422,022,022,032,012,014,010,011,211,311,411,311,211,; Label: 0 Input: 322,312,314,reset,322,422,reset,122,022,reset,212,202,242,reset,reset,223,224,221,220,reset,224,reset,reset,322,220,reset,220,reset,; Label: 1 Input: 322,312,311,; Label: 0 Input: 322,reset,232,242,reset,223,221,reset,; Label: 1 Input: 322,332,312,412,122,224,214,214,; Label: 0 Input: 444,; Label: 0 Input: 414,reset,022,032,034,; Label: 1 Input: 031,311,reset,212,232,242,202,reset,422,022,122,122,022,322,reset,223,221,reset,; Label: 1 Input: 444,333,211,121,422,422,242,224,224,; Label: 0 Input: reset,322,reset,202,reset,223,224,reset,; Label: 1 Input: 111,223,333,; Label: 0 Input: reset,422,422,422,442,442,442,442,444,444,444,444,reset,224,224,224,224,224,224,; Label: 0 Input: 322,422,122,reset,232,242,reset,223,224,reset,; Label: 1 Input: 304,reset,232,reset,323,reset,232,reset,223,224,; Label: 0 Input: reset,334,reset,201,reset,422,reset,232,reset,223,reset,; Label: 1 Input: 322,422,reset,232,242,reset,223,224,; Label: 0 Input: reset,242,reset,; Label: 0 Input: 232,342,322,reset,422,reset,232,reset,223,224,234,reset,322,reset,; Label: 1 Input: 322,332,232,232,232,reset,232,reset,223,; Label: 1 Input: 032,reset,322,022,322,202,232,242,202,reset,221,223,224,244,444,reset,422,142,144,141,241,240,243,reset,224,; Label: 1 Input: 232,reset,242,reset,322,322,322,322,322,322,322,reset,224,224,reset,044,044,044,044,044,044,044,044,044,044,044,044,044,044,044,044,044,044,044,044,044,reset,; Label: 1 Input: 322,422,122,reset,022,reset,232,242,212,202,reset,223,224,221,220,reset,; Label: 0 Input: 333,332,332,332,332,332,332,332,332,332,332,reset,reset,reset,reset,reset,322,322,422,422,422,422,422,422,422,reset,232,232,232,232,232,232,232,232,232,232,232,reset,223,223,223,223,223,223,223,223,223,223,; Label: 1 Input: 322,reset,232,reset,223,reset,232,reset,242,reset,212,reset,221,reset,; Label: 1 Input: 232,223,322,reset,322,reset,232,223,reset,444,444,444,444,444,444,444,444,444,444,444,444,444,444,444,444,444,444,reset,; Label: 1 Input: reset,322,342,242,223,; Label: 1 Input: 231,231,; Label: 0 Input: 322,reset,232,reset,220,reset,322,422,reset,242,232,232,232,232,232,reset,223,224,reset,; Label: 1 Input: 432,reset,322,reset,232,reset,224,reset,; Label: 1 Input: 322,332,333,; Label: 0 Input: 322,422,022,122,232,242,202,220,reset,224,220,223,224,223,220,; Label: 1 Input: 322,422,412,reset,232,242,202,202,202,202,202,202,202,202,reset,223,224,221,220,; Label: 1 Input: 322,422,432,423,424,reset,223,224,324,323,320,321,320,324,224,224,224,224,224,224,224,224,224,224,224,224,224,224,224,; Label: 0 Input: 444,442,432,332,111,000,020,020,020,; Label: 0 Input: 322,232,233,333,433,443,444,442,442,442,442,442,442,442,442,442,442,422,422,422,reset,232,reset,223,reset,; Label: 1 Input: reset,232,223,223,023,023,023,023,023,023,023,023,023,023,023,023,023,023,023,reset,; Label: 0 Input: reset,111,100,000,001,011,reset,011,011,011,reset,212,reset,122,reset,221,reset,; Label: 1 Input: 422,442,444,224,224,reset,223,232,reset,223,232,322,322,332,333,reset,232,233,; Label: 1 Input: 322,242,242,223,223,220,220,232,; Label: 1 Input: 333,333,333,220,400,reset,; Label: 0 Input: reset,reset,; Label: 0 Input: ; Label: 1 Input: 322,422,122,reset,232,242,reset,223,224,220,; Label: 1 Input: 131,reset,422,reset,242,reset,224,; Label: 1 Input: 322,reset,322,232,223,reset,322,332,333,334,344,444,333,334,343,433,reset,422,442,444,433,343,334,434,444,443,reset,422,reset,242,reset,224,224,reset,242,422,reset,; Label: 0 Input: 242,242,242,232,212,202,223,224,221,220,322,422,122,; Label: 1 Input: 232,242,212,202,212,232,242,reset,322,422,122,022,reset,223,224,221,220,reset,; Label: 1 Input: 122,322,232,242,212,223,223,224,232,232,232,; Label: 1 Input: 004,004,004,reset,040,040,040,040,reset,; Label: 0 Input: 332,322,333,333,333,333,333,333,reset,322,reset,232,reset,223,223,; Label: 1 Input: ; Label: 0 Input: 322,reset,232,reset,223,reset,232,reset,322,; Label: 1 Input: 322,122,232,212,242,202,224,220,221,reset,242,242,242,242,202,202,reset,224,224,224,reset,; Label: 1 Input: 322,422,122,022,reset,232,242,212,202,reset,223,224,221,220,; Label: 1 Input: 312,312,423,422,312,311,; Label: 0 Input: reset,422,022,reset,242,244,reset,224,reset,422,442,reset,242,reset,224,; Label: 1 Input: 313,444,044,024,034,233,233,233,233,233,; Label: 0 Input: 422,442,444,; Label: 0 Input: 111,111,112,reset,223,233,333,; Label: 1 Input: ; Label: 0 Input: 322,322,322,reset,232,232,232,reset,223,223,reset,; Label: 1 Input: 223,reset,422,122,022,reset,232,232,232,232,232,reset,322,322,322,reset,223,223,223,223,223,; Label: 1 Input: 213,212,412,442,440,; Label: 0 Input: 333,reset,322,reset,232,reset,224,reset,; Label: 1 Input: 422,022,022,242,242,242,220,220,220,220,220,220,220,; Label: 1 Input: 221,220,240,242,242,242,242,242,242,reset,242,242,242,242,reset,224,224,224,224,224,224,224,224,reset,242,242,242,242,242,242,242,242,242,242,242,242,242,242,reset,422,422,422,422,422,422,422,422,reset,; Label: 1 Input: 322,422,022,reset,232,242,202,reset,223,224,220,; Label: 1 Input: 322,302,304,reset,212,reset,232,231,221,321,324,314,214,214,214,214,214,214,214,214,214,; Label: 0 Input: ; Label: 0 Input: 322,232,232,232,223,223,; Label: 1 Input: 232,reset,242,reset,022,reset,422,reset,223,reset,; Label: 1 Input: reset,; Label: 0 Input: 322,122,022,012,122,132,134,132,232,332,232,232,reset,122,212,213,reset,322,232,221,; Label: 1 Input: 313,311,411,444,020,reset,reset,313,reset,223,reset,232,reset,322,reset,212,reset,; Label: 1 Input: 322,232,223,221,220,reset,; Label: 0 Input: 422,412,112,112,112,112,112,112,122,; Label: 0 Input: 422,242,202,223,224,242,242,422,422,422,; Label: 1 Input: 322,422,232,242,242,243,243,240,240,reset,220,220,322,322,322,323,reset,; Label: 1 Input: 332,reset,422,reset,242,reset,422,reset,242,reset,224,reset,; Label: 1 Input: 434,444,; Label: 0 Input: 422,422,022,022,232,232,212,212,213,213,213,214,214,214,; Label: 1 Input: 322,422,232,242,202,224,220,420,; Label: 0 Input: 322,reset,232,reset,223,223,223,233,233,333,333,reset,reset,; Label: 1 Input: 322,232,223,; Label: 1 Input: 134,000,000,000,000,000,000,000,000,000,000,reset,322,312,212,212,212,212,reset,223,223,223,223,223,223,; Label: 1 Input: 422,reset,242,242,reset,224,224,224,; Label: 1 Input: 122,122,132,130,; Label: 0 Input: 422,444,442,443,442,442,442,442,441,441,444,444,; Label: 0 Input: 322,232,reset,232,reset,223,reset,; Label: 1 Input: 232,322,322,reset,232,reset,322,reset,223,reset,; Label: 0 Input: 322,422,122,022,122,reset,232,242,202,242,202,reset,224,220,221,224,reset,; Label: 1 Input: 322,422,reset,242,242,242,242,224,224,224,224,224,224,reset,224,224,224,224,224,224,224,224,reset,; Label: 1 Input: 322,reset,232,223,reset,322,332,333,033,003,000,002,022,reset,322,322,reset,422,reset,242,reset,224,220,reset,220,reset,; Label: 1 Input: 422,242,224,reset,224,reset,; Label: 1 Input: 223,232,322,; Label: 0 Input: 310,213,022,422,322,242,212,220,223,224,; Label: 0 Input: reset,reset,reset,reset,reset,reset,reset,reset,reset,; Label: 0 Input: 322,422,022,122,reset,232,242,212,202,reset,223,224,220,221,reset,322,reset,232,reset,223,; Label: 1 Input: 322,322,322,322,322,322,322,322,322,322,322,322,322,322,322,322,reset,422,422,422,422,422,422,422,422,422,422,422,422,422,422,reset,242,242,242,242,242,242,242,242,242,242,reset,224,224,224,224,224,224,224,224,224,224,224,224,224,224,reset,220,220,220,220,220,220,220,220,220,; Label: 1 Input: reset,122,112,113,113,113,113,113,113,113,113,113,113,113,113,reset,221,111,000,000,000,000,000,000,000,000,004,004,004,004,004,; Label: 1 Input: 333,reset,440,reset,; Label: 0 Input: 122,232,221,223,322,232,223,; Label: 1 Input: ; Label: 1 Input: 322,reset,232,reset,232,reset,223,reset,; Label: 0 Input: 422,reset,242,reset,224,; Label: 1 Input: 322,reset,232,reset,322,reset,reset,223,reset,232,reset,322,122,022,reset,022,; Label: 0 Input: reset,; Label: 0 Input: 443,443,443,443,; Label: 0 Input: 331,331,331,; Label: 0 Input: 223,233,233,232,432,; Label: 0 Input: 223,reset,422,reset,242,224,; Label: 1 Input: reset,413,reset,223,reset,232,reset,322,reset,223,233,333,reset,322,reset,223,333,reset,322,332,reset,322,; Label: 1 Input: reset,322,022,032,reset,232,212,202,202,202,reset,223,224,221,220,220,220,reset,; Label: 1 Input: 444,131,040,044,401,402,102,101,100,104,132,332,342,442,442,442,322,321,311,011,011,011,011,011,; Label: 0 Input: 343,344,340,322,322,322,232,232,232,232,224,224,224,224,224,224,224,224,224,224,224,224,224,224,424,424,424,424,424,424,424,424,424,024,024,024,024,024,024,024,024,024,024,024,024,021,021,021,021,021,021,021,021,021,021,021,021,021,021,021,021,; Label: 1 Input: 212,223,223,322,; Label: 1 Input: 322,422,reset,022,reset,242,reset,242,reset,202,reset,224,reset,242,reset,; Label: 1 Input: 331,333,322,reset,322,reset,232,reset,224,220,; Label: 1 Input: reset,322,422,122,122,022,022,reset,232,232,202,242,242,reset,223,224,224,221,221,221,reset,232,232,244,reset,; Label: 1 Input: 322,422,122,reset,242,reset,223,reset,; Label: 0 Input: 224,220,224,224,224,224,224,224,224,224,224,224,224,224,224,reset,reset,224,224,224,224,242,242,202,202,422,422,422,422,422,422,424,424,424,424,424,reset,242,242,242,242,242,242,242,242,422,422,422,224,224,224,224,220,220,220,220,220,220,220,220,220,220,220,220,220,220,220,220,202,202,202,202,202,202,; Label: 0 Input: 224,reset,242,reset,422,reset,444,reset,212,reset,224,reset,242,reset,; Label: 1 Input: 422,022,242,reset,242,reset,224,reset,422,; Label: 1 Input: 322,232,232,232,221,221,223,212,122,reset,232,232,234,234,; Label: 1 Input: reset,; Label: 0 Input: 322,332,334,332,reset,reset,reset,422,reset,242,reset,reset,221,224,224,224,reset,; Label: 1 Input: 224,224,242,200,200,200,reset,242,242,242,reset,224,224,reset,422,422,422,reset,; Label: 1 Input: 322,422,022,reset,242,202,202,202,202,202,202,202,202,202,202,reset,242,242,242,242,242,242,242,reset,224,224,224,224,224,224,224,224,reset,220,220,220,220,220,220,reset,; Label: 1 Input: 221,221,221,221,221,221,221,221,221,221,221,221,221,221,221,221,221,221,221,reset,122,122,122,122,122,122,211,211,211,211,211,211,; Label: 0 Input: 322,223,reset,322,reset,232,232,232,reset,223,reset,122,112,111,221,221,221,212,122,; Label: 1 Input: 322,232,233,232,322,242,232,; Label: 1 Input: 322,232,223,224,; Label: 1 Input: 322,reset,232,232,232,reset,223,223,220,; Label: 1 Input: reset,; Label: 0 Input: reset,; Label: 0 Input: reset,112,reset,221,231,131,reset,223,reset,232,232,reset,322,reset,422,reset,242,reset,224,reset,122,reset,212,reset,221,; Label: 1 Input: 333,322,232,223,; Label: 0 Input: reset,reset,322,reset,232,reset,223,reset,322,reset,; Label: 1 Input: 312,312,312,312,312,312,; Label: 0 Input: 323,; Label: 0 Input: reset,reset,reset,322,332,333,; Label: 0 Input: reset,; Label: 0 Input: 422,422,422,422,422,422,422,422,422,422,422,422,422,422,422,422,422,022,022,022,022,022,022,022,022,022,022,022,022,022,022,022,022,reset,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,reset,223,223,224,224,220,220,221,reset,223,223,223,223,223,223,223,233,233,333,333,333,330,330,330,312,312,312,312,312,312,312,312,312,312,112,112,112,112,112,112,112,112,112,reset,322,322,322,322,322,322,322,322,reset,232,232,232,232,232,232,reset,223,223,223,; Label: 1 Input: 322,422,122,022,reset,232,242,212,202,reset,223,224,221,220,reset,; Label: 1 Input: 322,433,; Label: 0 Input: 313,314,reset,reset,333,reset,433,433,433,433,reset,332,reset,000,reset,232,332,reset,223,233,333,334,344,reset,232,332,333,334,344,444,; Label: 0 Input: 323,323,323,323,323,323,323,323,323,323,323,; Label: 0 Input: 322,reset,322,reset,232,reset,223,reset,; Label: 1 Input: 331,413,433,033,000,213,420,440,334,132,; Label: 0 Input: 422,442,444,reset,322,reset,232,reset,223,; Label: 1 Input: 313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,reset,322,322,322,reset,232,232,232,232,232,232,232,232,232,232,232,232,232,232,reset,223,223,223,223,223,reset,; Label: 1 Input: 422,422,022,022,022,242,242,242,242,202,202,202,202,202,202,202,224,224,224,224,221,221,221,221,221,reset,; Label: 1 Input: 223,213,413,013,023,013,033,reset,022,020,; Label: 0 Input: reset,reset,221,231,331,reset,; Label: 0 Input: 333,; Label: 0 Input: 422,422,242,242,242,224,224,224,224,224,224,224,reset,224,224,224,; Label: 1 Input: 224,; Label: 0 Input: 322,332,333,322,322,332,223,; Label: 0 Input: 413,413,113,110,140,240,221,231,231,231,231,231,231,231,231,031,031,031,011,001,; Label: 0 Input: 322,232,242,242,242,224,224,224,224,224,224,220,220,reset,223,; Label: 1 Input: 444,444,444,444,444,444,444,reset,012,012,012,012,012,012,012,012,012,012,012,012,012,012,012,012,reset,022,022,122,122,112,112,112,112,112,114,114,414,414,414,414,414,reset,422,422,422,reset,242,242,242,242,reset,224,224,224,; Label: 1 Input: 322,422,442,442,442,442,442,442,442,442,442,442,442,442,442,reset,232,232,232,232,reset,reset,223,223,223,223,223,223,reset,reset,; Label: 1 Input: 322,312,212,213,214,224,223,223,223,223,223,223,223,223,232,232,232,232,; Label: 1 Input: 322,322,322,322,322,reset,232,232,232,232,232,232,232,reset,223,223,223,223,223,223,; Label: 1 Input: 224,244,040,040,040,040,040,040,040,040,040,; Label: 0 Input: reset,reset,reset,333,333,reset,reset,232,232,232,242,242,reset,224,224,224,; Label: 1 Input: reset,reset,reset,322,reset,322,reset,232,reset,223,reset,223,reset,; Label: 1 Input: 444,431,300,111,000,000,444,444,444,; Label: 0 Input: 313,; Label: 0 Input: 422,reset,242,reset,224,; Label: 1 Input: 242,reset,224,reset,422,reset,242,reset,224,; Label: 1 Input: 322,322,322,322,322,322,322,reset,223,223,223,223,223,223,223,223,223,223,223,reset,232,232,232,232,232,232,232,; Label: 1 Input: 322,reset,442,242,reset,232,reset,242,422,reset,422,reset,224,220,202,422,; Label: 1 Input: 402,442,442,442,442,442,442,442,442,442,442,442,442,442,442,442,442,442,442,reset,422,424,; Label: 0 Input: reset,422,322,122,022,032,reset,022,422,442,reset,242,202,reset,422,reset,022,reset,242,202,reset,224,220,; Label: 1 Input: reset,332,332,333,333,reset,322,reset,232,reset,322,322,322,322,322,322,322,322,322,322,reset,232,232,232,232,232,232,232,232,232,232,232,reset,reset,reset,223,223,223,223,223,223,223,223,223,223,223,reset,reset,reset,223,223,223,reset,; Label: 1 Input: 322,332,232,reset,232,reset,223,333,333,333,333,333,333,333,333,333,333,333,333,333,333,333,333,reset,; Label: 1 Input: 413,; Label: 0 Input: 342,322,232,223,224,223,322,422,322,232,242,; Label: 0 Input: 224,reset,242,reset,422,reset,422,reset,242,reset,224,reset,; Label: 1 Input: reset,reset,reset,reset,; Label: 0 Input: reset,331,reset,224,reset,422,reset,reset,242,reset,224,; Label: 1 Input: 322,reset,422,242,224,reset,400,040,004,224,224,224,; Label: 0 Input: 322,422,reset,232,242,reset,224,; Label: 1 Input: reset,reset,reset,reset,reset,343,343,021,021,443,010,010,010,331,331,334,334,334,334,334,334,334,334,334,334,; Label: 0 Input: 122,212,221,reset,420,reset,242,reset,202,reset,202,reset,242,reset,232,reset,212,reset,223,reset,224,reset,221,reset,220,reset,232,reset,242,212,202,reset,; Label: 1 Input: reset,422,442,reset,220,200,200,200,reset,431,reset,431,reset,444,000,; Label: 0 Input: 322,122,022,022,002,002,302,301,301,301,301,301,reset,202,202,202,reset,224,224,224,224,224,224,224,; Label: 1 Input: 322,332,333,reset,322,232,223,224,224,224,224,224,224,224,424,424,424,424,424,424,424,424,024,024,024,024,024,024,024,024,024,024,024,024,024,024,024,024,024,024,020,020,020,020,020,020,020,020,020,020,020,020,020,020,020,020,020,242,242,242,242,242,242,242,242,242,242,242,242,242,242,242,242,242,242,242,242,242,242,242,242,242,202,202,202,202,202,202,202,202,202,202,202,202,202,202,202,202,202,202,202,202,202,; Label: 1 Input: 322,422,reset,232,reset,223,reset,; Label: 1 Input: reset,224,204,404,402,reset,reset,reset,422,reset,224,reset,242,reset,reset,reset,reset,reset,reset,000,000,000,000,000,000,reset,223,323,333,333,reset,111,111,112,112,122,122,122,122,122,reset,333,332,322,reset,112,112,; Label: 1 Input: reset,022,242,224,reset,322,reset,232,242,242,reset,223,224,; Label: 0 Input: 221,111,; Label: 0 Input: 224,reset,242,reset,422,reset,; Label: 1 Input: 322,322,reset,232,232,232,reset,223,223,223,223,reset,; Label: 1 Input: reset,333,; Label: 0 Input: 332,332,332,reset,; Label: 0 Input: 000,reset,322,322,reset,322,332,333,334,; Label: '}])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt-4\"\n",
        "response_list = []\n",
        "token_list = []\n",
        "for i, prompt_val in enumerate(prompts):\n",
        "    print(f\"Sample {i}:\")\n",
        "    response = client.chat.completions.create(\n",
        "      model = model_name,\n",
        "      messages = prompt_val,\n",
        "      seed = 523, # the date of running this code\n",
        "      temperature = 0\n",
        "    )\n",
        "    prediction = response.choices[0].message.content\n",
        "    token_list.append(response.usage.total_tokens)\n",
        "    print(prediction)\n",
        "    response_list.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvYIod3WtRUH",
        "outputId": "7befc27f-f087-4728-9391-30472a01684e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0:\n",
            "0\n",
            "Sample 1:\n",
            "1\n",
            "Sample 2:\n",
            "1\n",
            "Sample 3:\n",
            "1\n",
            "Sample 4:\n",
            "0\n",
            "Sample 5:\n",
            "0\n",
            "Sample 6:\n",
            "1\n",
            "Sample 7:\n",
            "1\n",
            "Sample 8:\n",
            "0\n",
            "Sample 9:\n",
            "0\n",
            "Sample 10:\n",
            "1\n",
            "Sample 11:\n",
            "0\n",
            "Sample 12:\n",
            "1\n",
            "Sample 13:\n",
            "0\n",
            "Sample 14:\n",
            "1\n",
            "Sample 15:\n",
            "0\n",
            "Sample 16:\n",
            "1\n",
            "Sample 17:\n",
            "0\n",
            "Sample 18:\n",
            "1\n",
            "Sample 19:\n",
            "0\n",
            "Sample 20:\n",
            "0\n",
            "Sample 21:\n",
            "1\n",
            "Sample 22:\n",
            "1\n",
            "Sample 23:\n",
            "0\n",
            "Sample 24:\n",
            "1\n",
            "Sample 25:\n",
            "1\n",
            "Sample 26:\n",
            "1\n",
            "Sample 27:\n",
            "1\n",
            "Sample 28:\n",
            "1\n",
            "Sample 29:\n",
            "1\n",
            "Sample 30:\n",
            "0\n",
            "Sample 31:\n",
            "1\n",
            "Sample 32:\n",
            "1\n",
            "Sample 33:\n",
            "0\n",
            "Sample 34:\n",
            "0\n",
            "Sample 35:\n",
            "0\n",
            "Sample 36:\n",
            "1\n",
            "Sample 37:\n",
            "1\n",
            "Sample 38:\n",
            "0\n",
            "Sample 39:\n",
            "1\n",
            "Sample 40:\n",
            "0\n",
            "Sample 41:\n",
            "0\n",
            "Sample 42:\n",
            "0\n",
            "Sample 43:\n",
            "1\n",
            "Sample 44:\n",
            "1\n",
            "Sample 45:\n",
            "0\n",
            "Sample 46:\n",
            "0\n",
            "Sample 47:\n",
            "1\n",
            "Sample 48:\n",
            "1\n",
            "Sample 49:\n",
            "1\n",
            "Sample 50:\n",
            "0\n",
            "Sample 51:\n",
            "0\n",
            "Sample 52:\n",
            "1\n",
            "Sample 53:\n",
            "1\n",
            "Sample 54:\n",
            "1\n",
            "Sample 55:\n",
            "0\n",
            "Sample 56:\n",
            "1\n",
            "Sample 57:\n",
            "1\n",
            "Sample 58:\n",
            "0\n",
            "Sample 59:\n",
            "0\n",
            "Sample 60:\n",
            "1\n",
            "Sample 61:\n",
            "1\n",
            "Sample 62:\n",
            "0\n",
            "Sample 63:\n",
            "1\n",
            "Sample 64:\n",
            "1\n",
            "Sample 65:\n",
            "0\n",
            "Sample 66:\n",
            "1\n",
            "Sample 67:\n",
            "0\n",
            "Sample 68:\n",
            "0\n",
            "Sample 69:\n",
            "1\n",
            "Sample 70:\n",
            "1\n",
            "Sample 71:\n",
            "0\n",
            "Sample 72:\n",
            "1\n",
            "Sample 73:\n",
            "0\n",
            "Sample 74:\n",
            "1\n",
            "Sample 75:\n",
            "1\n",
            "Sample 76:\n",
            "1\n",
            "Sample 77:\n",
            "1\n",
            "Sample 78:\n",
            "0\n",
            "Sample 79:\n",
            "1\n",
            "Sample 80:\n",
            "1\n",
            "Sample 81:\n",
            "1\n",
            "Sample 82:\n",
            "1\n",
            "Sample 83:\n",
            "0\n",
            "Sample 84:\n",
            "1\n",
            "Sample 85:\n",
            "1\n",
            "Sample 86:\n",
            "0\n",
            "Sample 87:\n",
            "1\n",
            "Sample 88:\n",
            "0\n",
            "Sample 89:\n",
            "1\n",
            "Sample 90:\n",
            "1\n",
            "Sample 91:\n",
            "1\n",
            "Sample 92:\n",
            "1\n",
            "Sample 93:\n",
            "1\n",
            "Sample 94:\n",
            "0\n",
            "Sample 95:\n",
            "1\n",
            "Sample 96:\n",
            "0\n",
            "Sample 97:\n",
            "0\n",
            "Sample 98:\n",
            "0\n",
            "Sample 99:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [int(pred) for pred in response_list]\n",
        "correct_predictions = sum([1.0 for true, pred in zip(labels_val, predictions) if true == pred])\n",
        "count_1 = sum(1.0 for x in labels_val if x == 1)\n",
        "accuracy = correct_predictions / len(labels_val)\n",
        "print(\"In-context (200 samples) Accuracy:\", accuracy)\n",
        "print(\"Number of samples in Class 1:\", count_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7aTibrAnFpw",
        "outputId": "b2377601-b473-4a6a-d2b9-82b9d34d9cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-context (200 samples) Accuracy: 0.78\n",
            "Number of samples in Class 1: 56.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = sum(1 for x in token_list if x > 8000)\n",
        "print(count)\n",
        "print(token_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K96wFdf6ndVj",
        "outputId": "3aa6555d-11ea-4664-a098-d34a4c420d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[7609, 7678, 7739, 7613, 7599, 7597, 7611, 7609, 7593, 7627, 7603, 7595, 7674, 7592, 7645, 7601, 7745, 7597, 7637, 7593, 7592, 7613, 7688, 7683, 7617, 7673, 7624, 7623, 7611, 7635, 7593, 7639, 7619, 7645, 7605, 7590, 7609, 7608, 7590, 7651, 7602, 7597, 7611, 7617, 7621, 7615, 7599, 7605, 7599, 7619, 7601, 7607, 7723, 7639, 7631, 7593, 7683, 7611, 7603, 7595, 7612, 7614, 7593, 7601, 7613, 7598, 7603, 7603, 7593, 7617, 7629, 7599, 7642, 7592, 7601, 7633, 7605, 7606, 7605, 7615, 7686, 7617, 7610, 7600, 7623, 7621, 7599, 7609, 7609, 7647, 7625, 7609, 7622, 7603, 7777, 7619, 7593, 7613, 7613, 7602]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The token length should be smaller than 8192, the maximum length of gpt-4 and gpt-3.5 turbo.\n"
      ],
      "metadata": {
        "id": "bQed6kUjw7-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training samples: 100"
      ],
      "metadata": {
        "id": "Gycc7_jpuOlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat_train_100 = dat_train.sample(n=100, random_state=523)\n",
        "prompts_incontext_100, labels_val = create_prompts(dat_train_100, dat_val)\n",
        "prompts_100 = create_chat_prompts(system_message, prompts_incontext_100)\n",
        "model_name = \"gpt-4\"\n",
        "response_list_100 = []\n",
        "token_list_100 = []\n",
        "for i, prompt_val in enumerate(prompts_100):\n",
        "    print(f\"Sample {i}:\")\n",
        "    response = client.chat.completions.create(\n",
        "      model = model_name,\n",
        "      messages = prompt_val,\n",
        "      seed = 523, # the date of running this code\n",
        "      temperature = 0\n",
        "    )\n",
        "    prediction = response.choices[0].message.content\n",
        "    token_list_100.append(response.usage.total_tokens)\n",
        "    print(prediction)\n",
        "    response_list_100.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir7dYpq8uUpj",
        "outputId": "7e5359ec-1186-4228-9a49-53f4f9faba06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0:\n",
            "0\n",
            "Sample 1:\n",
            "1\n",
            "Sample 2:\n",
            "1\n",
            "Sample 3:\n",
            "1\n",
            "Sample 4:\n",
            "0\n",
            "Sample 5:\n",
            "0\n",
            "Sample 6:\n",
            "1\n",
            "Sample 7:\n",
            "1\n",
            "Sample 8:\n",
            "0\n",
            "Sample 9:\n",
            "0\n",
            "Sample 10:\n",
            "1\n",
            "Sample 11:\n",
            "0\n",
            "Sample 12:\n",
            "1\n",
            "Sample 13:\n",
            "0\n",
            "Sample 14:\n",
            "1\n",
            "Sample 15:\n",
            "0\n",
            "Sample 16:\n",
            "1\n",
            "Sample 17:\n",
            "0\n",
            "Sample 18:\n",
            "1\n",
            "Sample 19:\n",
            "0\n",
            "Sample 20:\n",
            "0\n",
            "Sample 21:\n",
            "1\n",
            "Sample 22:\n",
            "1\n",
            "Sample 23:\n",
            "0\n",
            "Sample 24:\n",
            "1\n",
            "Sample 25:\n",
            "1\n",
            "Sample 26:\n",
            "1\n",
            "Sample 27:\n",
            "1\n",
            "Sample 28:\n",
            "1\n",
            "Sample 29:\n",
            "1\n",
            "Sample 30:\n",
            "0\n",
            "Sample 31:\n",
            "1\n",
            "Sample 32:\n",
            "1\n",
            "Sample 33:\n",
            "0\n",
            "Sample 34:\n",
            "1\n",
            "Sample 35:\n",
            "0\n",
            "Sample 36:\n",
            "1\n",
            "Sample 37:\n",
            "1\n",
            "Sample 38:\n",
            "0\n",
            "Sample 39:\n",
            "1\n",
            "Sample 40:\n",
            "0\n",
            "Sample 41:\n",
            "1\n",
            "Sample 42:\n",
            "0\n",
            "Sample 43:\n",
            "1\n",
            "Sample 44:\n",
            "1\n",
            "Sample 45:\n",
            "0\n",
            "Sample 46:\n",
            "0\n",
            "Sample 47:\n",
            "1\n",
            "Sample 48:\n",
            "0\n",
            "Sample 49:\n",
            "1\n",
            "Sample 50:\n",
            "0\n",
            "Sample 51:\n",
            "0\n",
            "Sample 52:\n",
            "1\n",
            "Sample 53:\n",
            "1\n",
            "Sample 54:\n",
            "1\n",
            "Sample 55:\n",
            "0\n",
            "Sample 56:\n",
            "1\n",
            "Sample 57:\n",
            "1\n",
            "Sample 58:\n",
            "0\n",
            "Sample 59:\n",
            "0\n",
            "Sample 60:\n",
            "1\n",
            "Sample 61:\n",
            "1\n",
            "Sample 62:\n",
            "0\n",
            "Sample 63:\n",
            "1\n",
            "Sample 64:\n",
            "1\n",
            "Sample 65:\n",
            "0\n",
            "Sample 66:\n",
            "1\n",
            "Sample 67:\n",
            "1\n",
            "Sample 68:\n",
            "0\n",
            "Sample 69:\n",
            "1\n",
            "Sample 70:\n",
            "1\n",
            "Sample 71:\n",
            "0\n",
            "Sample 72:\n",
            "1\n",
            "Sample 73:\n",
            "0\n",
            "Sample 74:\n",
            "1\n",
            "Sample 75:\n",
            "1\n",
            "Sample 76:\n",
            "1\n",
            "Sample 77:\n",
            "1\n",
            "Sample 78:\n",
            "1\n",
            "Sample 79:\n",
            "1\n",
            "Sample 80:\n",
            "1\n",
            "Sample 81:\n",
            "1\n",
            "Sample 82:\n",
            "1\n",
            "Sample 83:\n",
            "0\n",
            "Sample 84:\n",
            "1\n",
            "Sample 85:\n",
            "1\n",
            "Sample 86:\n",
            "0\n",
            "Sample 87:\n",
            "1\n",
            "Sample 88:\n",
            "0\n",
            "Sample 89:\n",
            "1\n",
            "Sample 90:\n",
            "1\n",
            "Sample 91:\n",
            "0\n",
            "Sample 92:\n",
            "1\n",
            "Sample 93:\n",
            "1\n",
            "Sample 94:\n",
            "0\n",
            "Sample 95:\n",
            "1\n",
            "Sample 96:\n",
            "0\n",
            "Sample 97:\n",
            "0\n",
            "Sample 98:\n",
            "0\n",
            "Sample 99:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [int(pred) for pred in response_list_100]\n",
        "correct_predictions = sum([1.0 for true, pred in zip(labels_val, predictions) if true == pred])\n",
        "accuracy = correct_predictions / len(labels_val)\n",
        "print(\"In-context (100 samples) Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac7cfZ_Ju5wF",
        "outputId": "aece22f5-895a-4905-994b-18382ee80c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-context (100 samples) Accuracy: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training samples: 50"
      ],
      "metadata": {
        "id": "QTifugBMu6y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat_train_50 = dat_train.sample(n=50, random_state=523)\n",
        "prompts_incontext_50, labels_val = create_prompts(dat_train_50, dat_val)\n",
        "prompts_50 = create_chat_prompts(system_message, prompts_incontext_50)\n",
        "model_name = \"gpt-4\"\n",
        "response_list_50 = []\n",
        "token_list_50 = []\n",
        "for i, prompt_val in enumerate(prompts_50):\n",
        "    print(f\"Sample {i}:\")\n",
        "    response = client.chat.completions.create(\n",
        "      model = model_name,\n",
        "      messages = prompt_val,\n",
        "      seed = 523, # the date of running this code\n",
        "      temperature = 0\n",
        "    )\n",
        "    prediction = response.choices[0].message.content\n",
        "    token_list_50.append(response.usage.total_tokens)\n",
        "    print(prediction)\n",
        "    response_list_50.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGuLF7UMu-G7",
        "outputId": "accd1efb-483d-4a92-d914-096e8a0ac77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0:\n",
            "0\n",
            "Sample 1:\n",
            "1\n",
            "Sample 2:\n",
            "1\n",
            "Sample 3:\n",
            "1\n",
            "Sample 4:\n",
            "1\n",
            "Sample 5:\n",
            "0\n",
            "Sample 6:\n",
            "1\n",
            "Sample 7:\n",
            "1\n",
            "Sample 8:\n",
            "0\n",
            "Sample 9:\n",
            "0\n",
            "Sample 10:\n",
            "1\n",
            "Sample 11:\n",
            "0\n",
            "Sample 12:\n",
            "1\n",
            "Sample 13:\n",
            "0\n",
            "Sample 14:\n",
            "1\n",
            "Sample 15:\n",
            "0\n",
            "Sample 16:\n",
            "1\n",
            "Sample 17:\n",
            "1\n",
            "Sample 18:\n",
            "1\n",
            "Sample 19:\n",
            "0\n",
            "Sample 20:\n",
            "0\n",
            "Sample 21:\n",
            "1\n",
            "Sample 22:\n",
            "1\n",
            "Sample 23:\n",
            "0\n",
            "Sample 24:\n",
            "1\n",
            "Sample 25:\n",
            "1\n",
            "Sample 26:\n",
            "1\n",
            "Sample 27:\n",
            "1\n",
            "Sample 28:\n",
            "1\n",
            "Sample 29:\n",
            "1\n",
            "Sample 30:\n",
            "0\n",
            "Sample 31:\n",
            "1\n",
            "Sample 32:\n",
            "1\n",
            "Sample 33:\n",
            "0\n",
            "Sample 34:\n",
            "1\n",
            "Sample 35:\n",
            "0\n",
            "Sample 36:\n",
            "1\n",
            "Sample 37:\n",
            "1\n",
            "Sample 38:\n",
            "0\n",
            "Sample 39:\n",
            "1\n",
            "Sample 40:\n",
            "0\n",
            "Sample 41:\n",
            "1\n",
            "Sample 42:\n",
            "0\n",
            "Sample 43:\n",
            "1\n",
            "Sample 44:\n",
            "1\n",
            "Sample 45:\n",
            "0\n",
            "Sample 46:\n",
            "1\n",
            "Sample 47:\n",
            "1\n",
            "Sample 48:\n",
            "0\n",
            "Sample 49:\n",
            "1\n",
            "Sample 50:\n",
            "0\n",
            "Sample 51:\n",
            "0\n",
            "Sample 52:\n",
            "1\n",
            "Sample 53:\n",
            "1\n",
            "Sample 54:\n",
            "1\n",
            "Sample 55:\n",
            "0\n",
            "Sample 56:\n",
            "1\n",
            "Sample 57:\n",
            "1\n",
            "Sample 58:\n",
            "0\n",
            "Sample 59:\n",
            "0\n",
            "Sample 60:\n",
            "1\n",
            "Sample 61:\n",
            "1\n",
            "Sample 62:\n",
            "0\n",
            "Sample 63:\n",
            "1\n",
            "Sample 64:\n",
            "1\n",
            "Sample 65:\n",
            "1\n",
            "Sample 66:\n",
            "1\n",
            "Sample 67:\n",
            "1\n",
            "Sample 68:\n",
            "0\n",
            "Sample 69:\n",
            "1\n",
            "Sample 70:\n",
            "1\n",
            "Sample 71:\n",
            "1\n",
            "Sample 72:\n",
            "1\n",
            "Sample 73:\n",
            "0\n",
            "Sample 74:\n",
            "1\n",
            "Sample 75:\n",
            "1\n",
            "Sample 76:\n",
            "1\n",
            "Sample 77:\n",
            "1\n",
            "Sample 78:\n",
            "1\n",
            "Sample 79:\n",
            "1\n",
            "Sample 80:\n",
            "1\n",
            "Sample 81:\n",
            "1\n",
            "Sample 82:\n",
            "1\n",
            "Sample 83:\n",
            "0\n",
            "Sample 84:\n",
            "1\n",
            "Sample 85:\n",
            "1\n",
            "Sample 86:\n",
            "1\n",
            "Sample 87:\n",
            "1\n",
            "Sample 88:\n",
            "0\n",
            "Sample 89:\n",
            "1\n",
            "Sample 90:\n",
            "1\n",
            "Sample 91:\n",
            "0\n",
            "Sample 92:\n",
            "1\n",
            "Sample 93:\n",
            "1\n",
            "Sample 94:\n",
            "0\n",
            "Sample 95:\n",
            "1\n",
            "Sample 96:\n",
            "0\n",
            "Sample 97:\n",
            "1\n",
            "Sample 98:\n",
            "0\n",
            "Sample 99:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [int(pred) for pred in response_list_50]\n",
        "correct_predictions = sum([1.0 for true, pred in zip(labels_val, predictions) if true == pred])\n",
        "accuracy = correct_predictions / len(labels_val)\n",
        "print(\"In-context (50 samples) Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNtlNHoavBIU",
        "outputId": "ec9defe6-8693-4fc8-ba12-5f6114fe1490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-context (50 samples) Accuracy: 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training samples: 25"
      ],
      "metadata": {
        "id": "RMnPL7eL7fQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat_train_25 = dat_train.sample(n=25, random_state=523)\n",
        "prompts_incontext_25, labels_val = create_prompts(dat_train_25, dat_val)\n",
        "prompts_25 = create_chat_prompts(system_message, prompts_incontext_25)\n",
        "model_name = \"gpt-4\"\n",
        "response_list_25 = []\n",
        "token_list_25 = []\n",
        "for i, prompt_val in enumerate(prompts_25):\n",
        "    print(f\"Sample {i}:\")\n",
        "    response = client.chat.completions.create(\n",
        "      model = model_name,\n",
        "      messages = prompt_val,\n",
        "      seed = 523, # the date of running this code\n",
        "      temperature = 0\n",
        "    )\n",
        "    prediction = response.choices[0].message.content\n",
        "    token_list_25.append(response.usage.total_tokens)\n",
        "    print(prediction)\n",
        "    response_list_25.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvH2oe4x7iRI",
        "outputId": "d78f5a02-98f7-4e46-a90a-c417b6e48ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0:\n",
            "0\n",
            "Sample 1:\n",
            "1\n",
            "Sample 2:\n",
            "1\n",
            "Sample 3:\n",
            "1\n",
            "Sample 4:\n",
            "0\n",
            "Sample 5:\n",
            "0\n",
            "Sample 6:\n",
            "1\n",
            "Sample 7:\n",
            "0\n",
            "Sample 8:\n",
            "0\n",
            "Sample 9:\n",
            "0\n",
            "Sample 10:\n",
            "0\n",
            "Sample 11:\n",
            "0\n",
            "Sample 12:\n",
            "0\n",
            "Sample 13:\n",
            "0\n",
            "Sample 14:\n",
            "1\n",
            "Sample 15:\n",
            "0\n",
            "Sample 16:\n",
            "1\n",
            "Sample 17:\n",
            "0\n",
            "Sample 18:\n",
            "0\n",
            "Sample 19:\n",
            "0\n",
            "Sample 20:\n",
            "0\n",
            "Sample 21:\n",
            "1\n",
            "Sample 22:\n",
            "1\n",
            "Sample 23:\n",
            "0\n",
            "Sample 24:\n",
            "0\n",
            "Sample 25:\n",
            "1\n",
            "Sample 26:\n",
            "1\n",
            "Sample 27:\n",
            "1\n",
            "Sample 28:\n",
            "1\n",
            "Sample 29:\n",
            "1\n",
            "Sample 30:\n",
            "0\n",
            "Sample 31:\n",
            "1\n",
            "Sample 32:\n",
            "1\n",
            "Sample 33:\n",
            "0\n",
            "Sample 34:\n",
            "0\n",
            "Sample 35:\n",
            "0\n",
            "Sample 36:\n",
            "0\n",
            "Sample 37:\n",
            "1\n",
            "Sample 38:\n",
            "0\n",
            "Sample 39:\n",
            "1\n",
            "Sample 40:\n",
            "0\n",
            "Sample 41:\n",
            "0\n",
            "Sample 42:\n",
            "0\n",
            "Sample 43:\n",
            "1\n",
            "Sample 44:\n",
            "1\n",
            "Sample 45:\n",
            "0\n",
            "Sample 46:\n",
            "0\n",
            "Sample 47:\n",
            "0\n",
            "Sample 48:\n",
            "0\n",
            "Sample 49:\n",
            "0\n",
            "Sample 50:\n",
            "0\n",
            "Sample 51:\n",
            "0\n",
            "Sample 52:\n",
            "1\n",
            "Sample 53:\n",
            "0\n",
            "Sample 54:\n",
            "1\n",
            "Sample 55:\n",
            "0\n",
            "Sample 56:\n",
            "1\n",
            "Sample 57:\n",
            "1\n",
            "Sample 58:\n",
            "0\n",
            "Sample 59:\n",
            "0\n",
            "Sample 60:\n",
            "1\n",
            "Sample 61:\n",
            "1\n",
            "Sample 62:\n",
            "0\n",
            "Sample 63:\n",
            "1\n",
            "Sample 64:\n",
            "1\n",
            "Sample 65:\n",
            "0\n",
            "Sample 66:\n",
            "1\n",
            "Sample 67:\n",
            "0\n",
            "Sample 68:\n",
            "0\n",
            "Sample 69:\n",
            "0\n",
            "Sample 70:\n",
            "1\n",
            "Sample 71:\n",
            "0\n",
            "Sample 72:\n",
            "1\n",
            "Sample 73:\n",
            "0\n",
            "Sample 74:\n",
            "0\n",
            "Sample 75:\n",
            "1\n",
            "Sample 76:\n",
            "1\n",
            "Sample 77:\n",
            "1\n",
            "Sample 78:\n",
            "1\n",
            "Sample 79:\n",
            "1\n",
            "Sample 80:\n",
            "1\n",
            "Sample 81:\n",
            "1\n",
            "Sample 82:\n",
            "1\n",
            "Sample 83:\n",
            "0\n",
            "Sample 84:\n",
            "1\n",
            "Sample 85:\n",
            "0\n",
            "Sample 86:\n",
            "0\n",
            "Sample 87:\n",
            "0\n",
            "Sample 88:\n",
            "0\n",
            "Sample 89:\n",
            "0\n",
            "Sample 90:\n",
            "1\n",
            "Sample 91:\n",
            "0\n",
            "Sample 92:\n",
            "0\n",
            "Sample 93:\n",
            "1\n",
            "Sample 94:\n",
            "0\n",
            "Sample 95:\n",
            "1\n",
            "Sample 96:\n",
            "0\n",
            "Sample 97:\n",
            "0\n",
            "Sample 98:\n",
            "0\n",
            "Sample 99:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [int(pred) for pred in response_list_25]\n",
        "correct_predictions = sum([1.0 for true, pred in zip(labels_val, predictions) if true == pred])\n",
        "accuracy = correct_predictions / len(labels_val)\n",
        "print(\"In-context (25 samples) Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1isKeI073FZ",
        "outputId": "839aa9ad-3704-45e8-af3a-89b3f4e56aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-context (25 samples) Accuracy: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 samples"
      ],
      "metadata": {
        "id": "Cr3qrgov-57G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat_train_5 = dat_train.sample(n=5, random_state=523)\n",
        "prompts_incontext_5, labels_val = create_prompts(dat_train_5, dat_val)\n",
        "prompts_5 = create_chat_prompts(system_message, prompts_incontext_5)\n",
        "model_name = \"gpt-4\"\n",
        "response_list_5 = []\n",
        "token_list_5 = []\n",
        "for i, prompt_val in enumerate(prompts_5):\n",
        "    print(f\"Sample {i}:\")\n",
        "    response = client.chat.completions.create(\n",
        "      model = model_name,\n",
        "      messages = prompt_val,\n",
        "      seed = 523, # the date of running this code\n",
        "      temperature = 0\n",
        "    )\n",
        "    prediction = response.choices[0].message.content\n",
        "    token_list_5.append(response.usage.total_tokens)\n",
        "    print(prediction)\n",
        "    response_list_5.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6qw-OL18QeR",
        "outputId": "dc028a59-fe39-41f9-a81d-2a508c2addfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0:\n",
            "1\n",
            "Sample 1:\n",
            "1\n",
            "Sample 2:\n",
            "1\n",
            "Sample 3:\n",
            "1\n",
            "Sample 4:\n",
            "1\n",
            "Sample 5:\n",
            "1\n",
            "Sample 6:\n",
            "1\n",
            "Sample 7:\n",
            "1\n",
            "Sample 8:\n",
            "1\n",
            "Sample 9:\n",
            "0\n",
            "Sample 10:\n",
            "1\n",
            "Sample 11:\n",
            "1\n",
            "Sample 12:\n",
            "0\n",
            "Sample 13:\n",
            "0\n",
            "Sample 14:\n",
            "1\n",
            "Sample 15:\n",
            "0\n",
            "Sample 16:\n",
            "1\n",
            "Sample 17:\n",
            "1\n",
            "Sample 18:\n",
            "1\n",
            "Sample 19:\n",
            "1\n",
            "Sample 20:\n",
            "0\n",
            "Sample 21:\n",
            "1\n",
            "Sample 22:\n",
            "0\n",
            "Sample 23:\n",
            "0\n",
            "Sample 24:\n",
            "1\n",
            "Sample 25:\n",
            "1\n",
            "Sample 26:\n",
            "1\n",
            "Sample 27:\n",
            "1\n",
            "Sample 28:\n",
            "1\n",
            "Sample 29:\n",
            "1\n",
            "Sample 30:\n",
            "1\n",
            "Sample 31:\n",
            "1\n",
            "Sample 32:\n",
            "1\n",
            "Sample 33:\n",
            "0\n",
            "Sample 34:\n",
            "1\n",
            "Sample 35:\n",
            "0\n",
            "Sample 36:\n",
            "1\n",
            "Sample 37:\n",
            "1\n",
            "Sample 38:\n",
            "0\n",
            "Sample 39:\n",
            "1\n",
            "Sample 40:\n",
            "1\n",
            "Sample 41:\n",
            "1\n",
            "Sample 42:\n",
            "0\n",
            "Sample 43:\n",
            "1\n",
            "Sample 44:\n",
            "0\n",
            "Sample 45:\n",
            "1\n",
            "Sample 46:\n",
            "1\n",
            "Sample 47:\n",
            "1\n",
            "Sample 48:\n",
            "0\n",
            "Sample 49:\n",
            "1\n",
            "Sample 50:\n",
            "1\n",
            "Sample 51:\n",
            "1\n",
            "Sample 52:\n",
            "1\n",
            "Sample 53:\n",
            "1\n",
            "Sample 54:\n",
            "1\n",
            "Sample 55:\n",
            "1\n",
            "Sample 56:\n",
            "1\n",
            "Sample 57:\n",
            "1\n",
            "Sample 58:\n",
            "1\n",
            "Sample 59:\n",
            "0\n",
            "Sample 60:\n",
            "1\n",
            "Sample 61:\n",
            "1\n",
            "Sample 62:\n",
            "1\n",
            "Sample 63:\n",
            "0\n",
            "Sample 64:\n",
            "1\n",
            "Sample 65:\n",
            "1\n",
            "Sample 66:\n",
            "1\n",
            "Sample 67:\n",
            "1\n",
            "Sample 68:\n",
            "0\n",
            "Sample 69:\n",
            "1\n",
            "Sample 70:\n",
            "1\n",
            "Sample 71:\n",
            "1\n",
            "Sample 72:\n",
            "1\n",
            "Sample 73:\n",
            "0\n",
            "Sample 74:\n",
            "1\n",
            "Sample 75:\n",
            "1\n",
            "Sample 76:\n",
            "1\n",
            "Sample 77:\n",
            "1\n",
            "Sample 78:\n",
            "1\n",
            "Sample 79:\n",
            "1\n",
            "Sample 80:\n",
            "0\n",
            "Sample 81:\n",
            "1\n",
            "Sample 82:\n",
            "1\n",
            "Sample 83:\n",
            "1\n",
            "Sample 84:\n",
            "1\n",
            "Sample 85:\n",
            "1\n",
            "Sample 86:\n",
            "1\n",
            "Sample 87:\n",
            "1\n",
            "Sample 88:\n",
            "0\n",
            "Sample 89:\n",
            "1\n",
            "Sample 90:\n",
            "1\n",
            "Sample 91:\n",
            "1\n",
            "Sample 92:\n",
            "1\n",
            "Sample 93:\n",
            "1\n",
            "Sample 94:\n",
            "0\n",
            "Sample 95:\n",
            "1\n",
            "Sample 96:\n",
            "1\n",
            "Sample 97:\n",
            "1\n",
            "Sample 98:\n",
            "1\n",
            "Sample 99:\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [int(pred) for pred in response_list_5]\n",
        "correct_predictions = sum([1.0 for true, pred in zip(labels_val, predictions) if true == pred])\n",
        "accuracy = correct_predictions / len(labels_val)\n",
        "print(\"In-context (25 samples) Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woJRGMpW-3JD",
        "outputId": "35fa0fec-2603-4892-e01c-fb6b5d80a36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-context (25 samples) Accuracy: 0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save data"
      ],
      "metadata": {
        "id": "2O_xKbLE9MGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat_train.to_csv('dat_train.csv', index=False)\n",
        "dat_val.to_csv('dat_val.csv', index=False)\n",
        "labels_val_df = pd.DataFrame(labels_val, columns=['label_val'])\n",
        "labels_val_df.to_csv('labels_val.csv', index=False)\n",
        "\n",
        "# For response_list, assuming it is also a list of responses\n",
        "response_list_df = pd.DataFrame(response_list, columns=['response'])\n",
        "response_list_df.to_csv('response_list.csv', index=False)\n",
        "\n",
        "# For response_list_100, assuming it is a list of responses\n",
        "response_list_100_df = pd.DataFrame(response_list_100, columns=['response'])\n",
        "response_list_100_df.to_csv('response_list_100.csv', index=False)\n",
        "\n",
        "# For response_list_100, assuming it is a list of responses\n",
        "response_list_50_df = pd.DataFrame(response_list_50, columns=['response'])\n",
        "response_list_50_df.to_csv('response_list_50.csv', index=False)\n",
        "\n",
        "# For response_list_100, assuming it is a list of responses\n",
        "response_list_25_df = pd.DataFrame(response_list_25, columns=['response'])\n",
        "response_list_25_df.to_csv('response_list_25.csv', index=False)\n",
        "\n",
        "# For response_list_100, assuming it is a list of responses\n",
        "response_list_5_df = pd.DataFrame(response_list_5, columns=['response'])\n",
        "response_list_5_df.to_csv('response_list_5.csv', index=False)"
      ],
      "metadata": {
        "id": "by0IBugz9OCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gpt3.5 for in-context sample size=25,5"
      ],
      "metadata": {
        "id": "RwCP33EY_d2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat_train_25 = dat_train.sample(n=25, random_state=523)\n",
        "prompts_incontext_25, labels_val = create_prompts(dat_train_25, dat_val)\n",
        "prompts_25 = create_chat_prompts(system_message, prompts_incontext_25)\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "response_list_25 = []\n",
        "token_list_25 = []\n",
        "for i, prompt_val in enumerate(prompts_25):\n",
        "    print(f\"Sample {i}:\")\n",
        "    response = client.chat.completions.create(\n",
        "      model = model_name,\n",
        "      messages = prompt_val,\n",
        "      seed = 523, # the date of running this code\n",
        "      temperature = 0\n",
        "    )\n",
        "    prediction = response.choices[0].message.content\n",
        "    token_list_25.append(response.usage.total_tokens)\n",
        "    print(prediction)\n",
        "    response_list_25.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uARM8Wx_dan",
        "outputId": "a31b5da5-3590-4944-f409-5a06a11ba5b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0:\n",
            "1\n",
            "Sample 1:\n",
            "1\n",
            "Sample 2:\n",
            "1\n",
            "Sample 3:\n",
            "1\n",
            "Sample 4:\n",
            "1\n",
            "Sample 5:\n",
            "1\n",
            "Sample 6:\n",
            "1\n",
            "Sample 7:\n",
            "1\n",
            "Sample 8:\n",
            "1\n",
            "Sample 9:\n",
            "1\n",
            "Sample 10:\n",
            "1\n",
            "Sample 11:\n",
            "1\n",
            "Sample 12:\n",
            "1\n",
            "Sample 13:\n",
            "1\n",
            "Sample 14:\n",
            "1\n",
            "Sample 15:\n",
            "1\n",
            "Sample 16:\n",
            "1\n",
            "Sample 17:\n",
            "1\n",
            "Sample 18:\n",
            "1\n",
            "Sample 19:\n",
            "1\n",
            "Sample 20:\n",
            "1\n",
            "Sample 21:\n",
            "1\n",
            "Sample 22:\n",
            "1\n",
            "Sample 23:\n",
            "1\n",
            "Sample 24:\n",
            "1\n",
            "Sample 25:\n",
            "1\n",
            "Sample 26:\n",
            "1\n",
            "Sample 27:\n",
            "1\n",
            "Sample 28:\n",
            "1\n",
            "Sample 29:\n",
            "1\n",
            "Sample 30:\n",
            "1\n",
            "Sample 31:\n",
            "1\n",
            "Sample 32:\n",
            "1\n",
            "Sample 33:\n",
            "1\n",
            "Sample 34:\n",
            "1\n",
            "Sample 35:\n",
            "1\n",
            "Sample 36:\n",
            "1\n",
            "Sample 37:\n",
            "1\n",
            "Sample 38:\n",
            "1\n",
            "Sample 39:\n",
            "1\n",
            "Sample 40:\n",
            "1\n",
            "Sample 41:\n",
            "1\n",
            "Sample 42:\n",
            "1\n",
            "Sample 43:\n",
            "1\n",
            "Sample 44:\n",
            "1\n",
            "Sample 45:\n",
            "1\n",
            "Sample 46:\n",
            "1\n",
            "Sample 47:\n",
            "1\n",
            "Sample 48:\n",
            "1\n",
            "Sample 49:\n",
            "1\n",
            "Sample 50:\n",
            "1\n",
            "Sample 51:\n",
            "1\n",
            "Sample 52:\n",
            "1\n",
            "Sample 53:\n",
            "1\n",
            "Sample 54:\n",
            "1\n",
            "Sample 55:\n",
            "1\n",
            "Sample 56:\n",
            "0\n",
            "Sample 57:\n",
            "1\n",
            "Sample 58:\n",
            "1\n",
            "Sample 59:\n",
            "1\n",
            "Sample 60:\n",
            "1\n",
            "Sample 61:\n",
            "1\n",
            "Sample 62:\n",
            "1\n",
            "Sample 63:\n",
            "1\n",
            "Sample 64:\n",
            "1\n",
            "Sample 65:\n",
            "1\n",
            "Sample 66:\n",
            "1\n",
            "Sample 67:\n",
            "1\n",
            "Sample 68:\n",
            "1\n",
            "Sample 69:\n",
            "1\n",
            "Sample 70:\n",
            "1\n",
            "Sample 71:\n",
            "1\n",
            "Sample 72:\n",
            "1\n",
            "Sample 73:\n",
            "1\n",
            "Sample 74:\n",
            "1\n",
            "Sample 75:\n",
            "1\n",
            "Sample 76:\n",
            "1\n",
            "Sample 77:\n",
            "1\n",
            "Sample 78:\n",
            "1\n",
            "Sample 79:\n",
            "1\n",
            "Sample 80:\n",
            "1\n",
            "Sample 81:\n",
            "1\n",
            "Sample 82:\n",
            "1\n",
            "Sample 83:\n",
            "1\n",
            "Sample 84:\n",
            "1\n",
            "Sample 85:\n",
            "1\n",
            "Sample 86:\n",
            "1\n",
            "Sample 87:\n",
            "1\n",
            "Sample 88:\n",
            "1\n",
            "Sample 89:\n",
            "1\n",
            "Sample 90:\n",
            "1\n",
            "Sample 91:\n",
            "1\n",
            "Sample 92:\n",
            "1\n",
            "Sample 93:\n",
            "1\n",
            "Sample 94:\n",
            "1\n",
            "Sample 95:\n",
            "1\n",
            "Sample 96:\n",
            "1\n",
            "Sample 97:\n",
            "1\n",
            "Sample 98:\n",
            "1\n",
            "Sample 99:\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [int(pred) for pred in response_list_25]\n",
        "correct_predictions = sum([1.0 for true, pred in zip(labels_val, predictions) if true == pred])\n",
        "accuracy = correct_predictions / len(labels_val)\n",
        "print(\"In-context (25 samples) Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h11onTbVAJEE",
        "outputId": "e6774055-1a92-4764-ed12-ac062001021a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-context (25 samples) Accuracy: 0.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dat_train_5 = dat_train.sample(n=5, random_state=523)\n",
        "prompts_incontext_5, labels_val = create_prompts(dat_train_5, dat_val)\n",
        "prompts_5 = create_chat_prompts(system_message, prompts_incontext_5)\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "response_list_5 = []\n",
        "token_list_5 = []\n",
        "for i, prompt_val in enumerate(prompts_5):\n",
        "    print(f\"Sample {i}:\")\n",
        "    response = client.chat.completions.create(\n",
        "      model = model_name,\n",
        "      messages = prompt_val,\n",
        "      seed = 523, # the date of running this code\n",
        "      temperature = 0\n",
        "    )\n",
        "    prediction = response.choices[0].message.content\n",
        "    token_list_5.append(response.usage.total_tokens)\n",
        "    print(prediction)\n",
        "    response_list_5.append(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiVpLi4CAMbq",
        "outputId": "05b5339b-cbb4-4c8c-af72-bc3dbbc73a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0:\n",
            "1\n",
            "Sample 1:\n",
            "1\n",
            "Sample 2:\n",
            "1\n",
            "Sample 3:\n",
            "1\n",
            "Sample 4:\n",
            "1\n",
            "Sample 5:\n",
            "1\n",
            "Sample 6:\n",
            "1\n",
            "Sample 7:\n",
            "1\n",
            "Sample 8:\n",
            "1\n",
            "Sample 9:\n",
            "1\n",
            "Sample 10:\n",
            "1\n",
            "Sample 11:\n",
            "1\n",
            "Sample 12:\n",
            "1\n",
            "Sample 13:\n",
            "1\n",
            "Sample 14:\n",
            "1\n",
            "Sample 15:\n",
            "1\n",
            "Sample 16:\n",
            "1\n",
            "Sample 17:\n",
            "1\n",
            "Sample 18:\n",
            "1\n",
            "Sample 19:\n",
            "1\n",
            "Sample 20:\n",
            "1\n",
            "Sample 21:\n",
            "1\n",
            "Sample 22:\n",
            "1\n",
            "Sample 23:\n",
            "1\n",
            "Sample 24:\n",
            "1\n",
            "Sample 25:\n",
            "1\n",
            "Sample 26:\n",
            "1\n",
            "Sample 27:\n",
            "1\n",
            "Sample 28:\n",
            "1\n",
            "Sample 29:\n",
            "1\n",
            "Sample 30:\n",
            "1\n",
            "Sample 31:\n",
            "1\n",
            "Sample 32:\n",
            "1\n",
            "Sample 33:\n",
            "1\n",
            "Sample 34:\n",
            "1\n",
            "Sample 35:\n",
            "1\n",
            "Sample 36:\n",
            "1\n",
            "Sample 37:\n",
            "1\n",
            "Sample 38:\n",
            "1\n",
            "Sample 39:\n",
            "1\n",
            "Sample 40:\n",
            "0\n",
            "Sample 41:\n",
            "1\n",
            "Sample 42:\n",
            "1\n",
            "Sample 43:\n",
            "1\n",
            "Sample 44:\n",
            "1\n",
            "Sample 45:\n",
            "1\n",
            "Sample 46:\n",
            "1\n",
            "Sample 47:\n",
            "1\n",
            "Sample 48:\n",
            "1\n",
            "Sample 49:\n",
            "1\n",
            "Sample 50:\n",
            "1\n",
            "Sample 51:\n",
            "1\n",
            "Sample 52:\n",
            "1\n",
            "Sample 53:\n",
            "1\n",
            "Sample 54:\n",
            "1\n",
            "Sample 55:\n",
            "1\n",
            "Sample 56:\n",
            "1\n",
            "Sample 57:\n",
            "1\n",
            "Sample 58:\n",
            "1\n",
            "Sample 59:\n",
            "1\n",
            "Sample 60:\n",
            "1\n",
            "Sample 61:\n",
            "1\n",
            "Sample 62:\n",
            "1\n",
            "Sample 63:\n",
            "1\n",
            "Sample 64:\n",
            "1\n",
            "Sample 65:\n",
            "1\n",
            "Sample 66:\n",
            "1\n",
            "Sample 67:\n",
            "1\n",
            "Sample 68:\n",
            "1\n",
            "Sample 69:\n",
            "1\n",
            "Sample 70:\n",
            "1\n",
            "Sample 71:\n",
            "1\n",
            "Sample 72:\n",
            "1\n",
            "Sample 73:\n",
            "1\n",
            "Sample 74:\n",
            "1\n",
            "Sample 75:\n",
            "1\n",
            "Sample 76:\n",
            "1\n",
            "Sample 77:\n",
            "1\n",
            "Sample 78:\n",
            "1\n",
            "Sample 79:\n",
            "1\n",
            "Sample 80:\n",
            "1\n",
            "Sample 81:\n",
            "1\n",
            "Sample 82:\n",
            "1\n",
            "Sample 83:\n",
            "1\n",
            "Sample 84:\n",
            "1\n",
            "Sample 85:\n",
            "1\n",
            "Sample 86:\n",
            "1\n",
            "Sample 87:\n",
            "1\n",
            "Sample 88:\n",
            "1\n",
            "Sample 89:\n",
            "1\n",
            "Sample 90:\n",
            "1\n",
            "Sample 91:\n",
            "1\n",
            "Sample 92:\n",
            "1\n",
            "Sample 93:\n",
            "1\n",
            "Sample 94:\n",
            "1\n",
            "Sample 95:\n",
            "1\n",
            "Sample 96:\n",
            "1\n",
            "Sample 97:\n",
            "1\n",
            "Sample 98:\n",
            "1\n",
            "Sample 99:\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [int(pred) for pred in response_list_5]\n",
        "correct_predictions = sum([1.0 for true, pred in zip(labels_val, predictions) if true == pred])\n",
        "accuracy = correct_predictions / len(labels_val)\n",
        "print(\"In-context (25 samples) Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqiwt6e7AvPp",
        "outputId": "1aead7eb-6312-4055-81ac-5d771eff8fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-context (25 samples) Accuracy: 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_a = [\n",
        "    [200, 0.78], [100, 0.76], [50, 0.73], [25, 0.70], [5, 0.62]\n",
        "]\n",
        "data_a.sort()\n",
        "data_b = [\n",
        "    [5, 0.57], [25, 0.55], [50, 0.56], [100, 0.54], [200, 0.57]\n",
        "]\n",
        "data_b.sort()\n",
        "\n",
        "in_context_samples = [x[0] for x in data_a]\n",
        "accuracy_a = [x[1] for x in data_a]\n",
        "accuracy_b = [x[1] for x in data_b]\n",
        "\n",
        "x = np.arange(len(in_context_samples))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, accuracy_a, width, label='GPT-4')\n",
        "rects2 = ax.bar(x + width/2, accuracy_b, width, label='GPT-3.5 Turbo')\n",
        "\n",
        "ax.set_xlabel('Number of In-context Samples')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(in_context_samples)\n",
        "ax.legend()\n",
        "\n",
        "plt.savefig('accuracy_gpt.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "_8NFag14BZQc",
        "outputId": "bba14846-7a4c-4855-9435-f4b45da86599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
